# Copyright (c) 2025, The Isaac Lab Arena Project Developers (https://github.com/isaac-sim/IsaacLab-Arena/blob/main/CONTRIBUTORS.md).
# All rights reserved.
#
# SPDX-License-Identifier: Apache-2.0

from collections.abc import Sequence
from dataclasses import MISSING

import isaaclab.envs.mdp as mdp
import isaaclab.utils.math as PoseUtils
from isaaclab.controllers.config.rmp_flow import AGIBOT_LEFT_ARM_RMPFLOW_CFG, AGIBOT_RIGHT_ARM_RMPFLOW_CFG
from isaaclab.envs.mdp.actions.rmpflow_actions_cfg import RMPFlowActionCfg
from isaaclab.managers import ObservationGroupCfg as ObsGroup
from isaaclab.managers import ObservationTermCfg as ObsTerm
from isaaclab.markers.config import FRAME_MARKER_CFG
from isaaclab.sensors.frame_transformer.frame_transformer_cfg import FrameTransformerCfg, OffsetCfg
from isaaclab.utils import configclass
from isaaclab_assets.robots.agibot import AGIBOT_A2D_CFG
from isaaclab_tasks.manager_based.manipulation.pick_place.mdp import get_robot_joint_state
from isaaclab_tasks.manager_based.manipulation.stack.mdp import ee_frame_pose_in_base_frame

from isaaclab_arena.assets.register import register_asset
from isaaclab_arena.embodiments.common.arm_mode import ArmMode
from isaaclab_arena.embodiments.embodiment_base import EmbodimentBase
from isaaclab_arena.embodiments.franka.franka import FrankaMimicEnv
from isaaclab_arena.utils.pose import Pose


@register_asset
class AgibotEmbodiment(EmbodimentBase):
    """Embodiment for the Agibot robot."""

    name = "agibot"
    default_arm_mode = ArmMode.LEFT

    def __init__(
        self, enable_cameras: bool = False, initial_pose: Pose | None = None, arm_mode: ArmMode = ArmMode.LEFT
    ):
        super().__init__(enable_cameras, initial_pose)
        self.arm_mode = arm_mode or self.default_arm_mode
        self.scene_config = AgibotLeftArmSceneCfg() if self.arm_mode == ArmMode.LEFT else AgibotRightArmSceneCfg()
        self.action_config = AgibotLeftArmActionsCfg() if self.arm_mode == ArmMode.LEFT else AgibotRightArmActionsCfg()
        self.observation_config = AgibotObservationsCfg()
        self.mimic_env = AgibotMimicEnv


@configclass
class AgibotSceneCfg:
    """Scene configuration for the Agibot."""

    robot = AGIBOT_A2D_CFG.replace(prim_path="{ENV_REGEX_NS}/Robot")

    ee_frame: FrameTransformerCfg = MISSING


@configclass
class AgibotLeftArmSceneCfg(AgibotSceneCfg):
    """Scene configuration for the Agibot left arm."""

    ee_frame = FrameTransformerCfg(
        prim_path="{ENV_REGEX_NS}/Robot/base_link",
        debug_vis=False,
        target_frames=[
            FrameTransformerCfg.FrameCfg(
                prim_path="{ENV_REGEX_NS}/Robot/gripper_center",
                name="left_end_effector",
                offset=OffsetCfg(
                    rot=(0.7071, 0.0, -0.7071, 0.0),
                ),
            ),
        ],
    )

    def __post_init__(self):
        # Add a marker to the end-effector frame
        marker_cfg = FRAME_MARKER_CFG.copy()
        marker_cfg.markers["frame"].scale = (0.1, 0.1, 0.1)
        marker_cfg.prim_path = "/Visuals/FrameTransformer"
        self.ee_frame.visualizer_cfg = marker_cfg


@configclass
class AgibotRightArmSceneCfg(AgibotSceneCfg):
    """Scene configuration for the Agibot right arm."""

    ee_frame = FrameTransformerCfg(
        prim_path="{ENV_REGEX_NS}/Robot/base_link",
        debug_vis=False,
        target_frames=[
            FrameTransformerCfg.FrameCfg(
                prim_path="{ENV_REGEX_NS}/Robot/right_gripper_center",
                name="right_end_effector",
            ),
        ],
    )

    def __post_init__(self):
        # Add a marker to the end-effector frame
        marker_cfg = FRAME_MARKER_CFG.copy()
        marker_cfg.markers["frame"].scale = (0.1, 0.1, 0.1)
        marker_cfg.prim_path = "/Visuals/FrameTransformer"
        self.ee_frame.visualizer_cfg = marker_cfg


@configclass
class AgibotLeftArmActionsCfg:
    """Action configuration for the Agibot left arm."""

    arm_action = RMPFlowActionCfg(
        asset_name="robot",
        joint_names=["left_arm_joint.*"],
        body_name="gripper_center",
        controller=AGIBOT_LEFT_ARM_RMPFLOW_CFG,
        scale=1.0,
        body_offset=RMPFlowActionCfg.OffsetCfg(rot=[0.7071, 0.0, -0.7071, 0.0]),
        articulation_prim_expr="/World/envs/env_.*/Robot",
        use_relative_mode=True,
    )

    gripper_action = mdp.BinaryJointPositionActionCfg(
        asset_name="robot",
        joint_names=["left_hand_joint1", "left_.*_Support_Joint"],
        open_command_expr={"left_hand_joint1": 0.994, "left_.*_Support_Joint": 0.994},
        close_command_expr={"left_hand_joint1": 0.0, "left_.*_Support_Joint": 0.0},
    )


@configclass
class AgibotRightArmActionsCfg:
    """Action configuration for the Agibot right arm."""

    arm_action = RMPFlowActionCfg(
        asset_name="robot",
        joint_names=["right_arm_joint.*"],
        body_name="right_gripper_center",
        controller=AGIBOT_RIGHT_ARM_RMPFLOW_CFG,
        scale=1.0,
        articulation_prim_expr="/World/envs/env_.*/Robot",
        use_relative_mode=True,
    )

    gripper_action = mdp.BinaryJointPositionActionCfg(
        asset_name="robot",
        joint_names=["right_hand_joint1", "right_.*_Support_Joint"],
        open_command_expr={"right_hand_joint1": 0.994, "right_.*_Support_Joint": 0.994},
        close_command_expr={"right_hand_joint1": 0.0, "right_.*_Support_Joint": 0.0},
    )


@configclass
class AgibotObservationsCfg:
    """Observation configuration for the Agibot robot."""

    @configclass
    class PolicyCfg(ObsGroup):
        """Observations for policy group with state values."""

        actions = ObsTerm(func=mdp.last_action)
        joint_pos = ObsTerm(func=mdp.joint_pos_rel)
        joint_vel = ObsTerm(func=mdp.joint_vel_rel)
        # since the robot may not located at the origin of env, we get the eef pose in the base frame
        eef_pos = ObsTerm(func=ee_frame_pose_in_base_frame, params={"return_key": "pos"})
        eef_quat = ObsTerm(func=ee_frame_pose_in_base_frame, params={"return_key": "quat"})
        left_gripper_pos = ObsTerm(
            func=get_robot_joint_state, params={"joint_names": ["left_hand_joint1", "left_Right_1_Joint"]}
        )
        right_gripper_pos = ObsTerm(
            func=get_robot_joint_state,
            params={"joint_names": ["right_hand_joint1", "right_Right_1_Joint"]},
        )

        def __post_init__(self):
            self.enable_corruption = False
            self.concatenate_terms = False

    # observation groups
    policy: PolicyCfg = PolicyCfg()


class AgibotMimicEnv(FrankaMimicEnv):
    """Configuration for Agibot Mimic."""

    def get_object_poses(self, env_ids: Sequence[int] | None = None):
        """
        Gets the pose of each object (including rigid objects and articulated objects) in the robot base frame.
        This should be aligned with the observation configuration, to ensure all the poses are expressed in the same frame.

        Args:
            env_ids: Environment indices to get the pose for. If None, all envs are considered.

        Returns:
            A dictionary that maps object names to object pose matrix in robot base frame (4x4 torch.Tensor)
        """
        if env_ids is None:
            env_ids = slice(None)

        # Get scene state
        scene_state = self.scene.get_state(is_relative=True)
        rigid_object_states = scene_state["rigid_object"]
        articulation_states = scene_state["articulation"]

        # Get robot root pose
        robot_root_pose = articulation_states["robot"]["root_pose"]
        root_pos = robot_root_pose[env_ids, :3]
        root_quat = robot_root_pose[env_ids, 3:7]

        object_pose_matrix = dict()

        # Process rigid objects
        for obj_name, obj_state in rigid_object_states.items():
            pos_obj_base, quat_obj_base = PoseUtils.subtract_frame_transforms(
                root_pos, root_quat, obj_state["root_pose"][env_ids, :3], obj_state["root_pose"][env_ids, 3:7]
            )
            rot_obj_base = PoseUtils.matrix_from_quat(quat_obj_base)
            object_pose_matrix[obj_name] = PoseUtils.make_pose(pos_obj_base, rot_obj_base)

        # Process articulated objects (except robot)
        for art_name, art_state in articulation_states.items():
            if art_name != "robot":  # Skip robot
                pos_obj_base, quat_obj_base = PoseUtils.subtract_frame_transforms(
                    root_pos, root_quat, art_state["root_pose"][env_ids, :3], art_state["root_pose"][env_ids, 3:7]
                )
                rot_obj_base = PoseUtils.matrix_from_quat(quat_obj_base)
                object_pose_matrix[art_name] = PoseUtils.make_pose(pos_obj_base, rot_obj_base)

        return object_pose_matrix
